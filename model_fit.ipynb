{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_data = pd.read_csv(r\"C:\\Users\\mjcanudo\\Documents\\Nova\\ML\\Project2\\datasets\\keep_data.csv\", index_col='Cust_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = keep_data.drop(columns=\"Buy_product\").copy()\n",
    "y = keep_data[\"Buy_product\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled = pd.DataFrame(scaled, columns=X.columns, index=X.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_model = PCA(n_components=2)\n",
    "df_reduced = pca_model.fit_transform(scaled)\n",
    "plt.scatter(df_reduced[:,0], df_reduced[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = pd.DataFrame(df_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_linear_model = SVC(kernel='linear', C=100)\n",
    "svm_linear_model.fit(df_x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the maximum margin separating hyperplane within a two-class separable dataset using a Support Vector Machine classifier with linear kernel.\n",
    "\n",
    "Source: https://scikit-learn.org/stable/auto_examples/svm/plot_separating_hyperplane.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_svm_boundary(model,X,y):\n",
    "    \n",
    "    X = X.values\n",
    "    y = y.values\n",
    "    \n",
    "    # Scatter Plot\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, s=30,cmap='seismic')\n",
    "\n",
    "    \n",
    "    # plot the decision function\n",
    "    ax = plt.gca()\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "\n",
    "    # create grid to evaluate model\n",
    "    xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "    yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "    YY, XX = np.meshgrid(yy, xx)\n",
    "    xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "    Z = model.decision_function(xy).reshape(XX.shape)\n",
    "\n",
    "    # plot decision boundary and margins\n",
    "    ax.contour(XX, YY, Z, colors='k', levels=[-1, 0, 1], alpha=0.5,\n",
    "               linestyles=['--', '-', '--'])\n",
    "    # plot support vectors\n",
    "    ax.scatter(model.support_vectors_[:, 0], model.support_vectors_[:, 1], s=100,\n",
    "               linewidth=1, facecolors='none', edgecolors='k')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data is not linearly separable, the linear kernel is not the appropriate option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try non-linear kernels on SVC like rbf and poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_svm_boundary(svm_linear_model, X=df_x, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gamma auto = 1/n of features\n",
    "svm_rbf_model = SVC(kernel='rbf', C=0.001, gamma=5)\n",
    "svm_rbf_model.fit(df_x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LAB 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "################################### MODEL SELECTION & OPTIMIZATION ########################################\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_models(data, model):\n",
    "    skf = StratifiedKFold(n_splits = 5, random_state = 99, shuffle = True)\n",
    "    X = data.drop('Buy_product', axis = 1)\n",
    "    y = data['Buy_product'].copy()\n",
    "\n",
    "    score_train, score_val = [],[]\n",
    "\n",
    "    # perform the cross-validation\n",
    "    for train_index, val_index in skf.split(X,y):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "        # Scale the data\n",
    "        scaler = MinMaxScaler().fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_val = scaler.transform(X_val)\n",
    "\n",
    "        # Apply model\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions_train = model.predict(X_train)\n",
    "        predictions_val = model.predict(X_val)\n",
    "        score_train.append(f1_score(y_train, predictions_train))\n",
    "        score_val.append(f1_score(y_val, predictions_val))\n",
    "\n",
    "    avg_train = round(np.mean(score_train),3)\n",
    "    avg_val = round(np.mean(score_val),3)\n",
    "    std_train = round(np.std(score_train),2)\n",
    "    std_val = round(np.std(score_val),2)\n",
    "\n",
    "    return avg_train, std_train, avg_val, std_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(df, data, *args):\n",
    "    count = 0\n",
    "    # for each instance of model passed as argument\n",
    "    for arg in args:\n",
    "        avg_train, std_train, avg_val, std_val = select_best_models(data, arg)\n",
    "        # store the results in the right row\n",
    "        df.iloc[count] = str(avg_train) + '+/-' + str(std_train), str(avg_val) + '+/-' + str(std_val)\n",
    "        count+=1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_rbf_model = SVC(kernel='rbf')\n",
    "svm_rbf_model_tunned = SVC(kernel='rbf', C=1, gamma=5)\n",
    "svm_poly_model = SVC(kernel='poly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.DataFrame(columns = ['Train','Validation'], index = ['RBF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results(df_all, keep_data, svm_rbf_model, svm_poly_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RBF</th>\n",
       "      <td>0.949+/-0.0</td>\n",
       "      <td>0.914+/-0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Train   Validation\n",
       "RBF  0.949+/-0.0  0.914+/-0.0"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_results(df_all, all_data, svm_rbf_model_tunned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_plot(train, validation, values_try):\n",
    "    sns.pointplot(x=values_try, y=train, color = 'teal', label = 'Train')\n",
    "    sns.pointplot(x=values_try, y=validation, color = 'goldenrod', label = 'Validation')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation:\n",
    "\n",
    "When training an SVM with the Radial Basis Function (RBF) kernel, two parameters must be considered: C and gamma. The parameter C, common to all SVM kernels, trades off misclassification of training examples against simplicity of the decision surface. A low C makes the decision surface smooth, while a high C aims at classifying all training examples correctly. gamma defines how much influence a single training example has. The larger gamma is, the closer other examples must be to be affected.\n",
    "\n",
    "Proper choice of C and gamma is critical to the SVMâ€™s performance. One is advised to use GridSearchCV with C and gamma spaced exponentially far apart to choose good values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_svm_rbf = {'C': [0.1, 1, 10, 100, 1000],  \n",
    "              'gamma': [7, 5, 3, 1, 0.1, 0.01, 0.001, 0.0001], \n",
    "              'kernel': ['rbf']}\n",
    "\n",
    "grid_search = GridSearchCV(SVC(),\n",
    "                        param_grid_svm_rbf,\n",
    "                        scoring = 'f1',\n",
    "                        return_train_score = True,\n",
    "                        cv = 5,\n",
    "                        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(df_scaled, y)\n",
    "\n",
    "# Print the best hyperparameters and corresponding score\n",
    "print(\"Best Hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best Score: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv(r\"C:\\Users\\mjcanudo\\Documents\\Nova\\ML\\Project2\\datasets\\all_data.csv\", index_col='Cust_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_X = all_data.drop(columns=\"Buy_product\").copy()\n",
    "all_data_y = all_data[\"Buy_product\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaled = scaler.fit_transform(all_data_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_X_scaled = pd.DataFrame(scaled, columns=all_data_X.columns, index=all_data_X.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_svm_rbf = {'C': [0.1, 0.3, 0.5, 1, 10, 100, 1000],  \n",
    "              'gamma': [7, 6, 5, 4, 3, 1, 0.1, 0.01], \n",
    "              'kernel': ['rbf']}\n",
    "\n",
    "grid_search = GridSearchCV(SVC(),\n",
    "                        param_grid_svm_rbf,\n",
    "                        scoring = 'f1',\n",
    "                        return_train_score = True,\n",
    "                        cv = 5,\n",
    "                        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 56 candidates, totalling 280 fits\n",
      "Best Hyperparameters:  {'C': 1, 'gamma': 5, 'kernel': 'rbf'}\n",
      "Best Score:  0.9148676589466327\n"
     ]
    }
   ],
   "source": [
    "grid_search.fit(all_data_X_scaled, all_data_y)\n",
    "\n",
    "# Print the best hyperparameters and corresponding score\n",
    "print(\"Best Hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best Score: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RBF</th>\n",
       "      <td>0.928+/-0.0</td>\n",
       "      <td>0.91+/-0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Train  Validation\n",
       "RBF  0.928+/-0.0  0.91+/-0.0"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_rbf_model_tunned = SVC(kernel='rbf', C=0.3, gamma=5)\n",
    "\n",
    "show_results(df_all, all_data, svm_rbf_model_tunned)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_nova",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
